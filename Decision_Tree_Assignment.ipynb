{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: What is a Decision Tree, and how does it work in the context of classification?\n",
        "\n",
        "**Ans:-** A Decision Tree is a supervised learning algorithm mostly used for classification tasks. It models decisions by recursively splitting the data into subsets based on feature values, creating nodes and branches. Each internal node represents a test on a feature, each branch an outcome, and each leaf node a class label. The tree is constructed by selecting splits that best separate the classes until a stopping criterion is met.\n",
        "\n",
        "# Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "\n",
        "**Ans:-** Gini Impurity measures the probability of incorrectly classifying a randomly chosen element. Lower Gini means purer splits.\n",
        "\n",
        "Entropy quantifies the disorder or uncertainty. Lower entropy means more confident predictions.\n",
        "\n",
        "Both are used to evaluate splits: the algorithm chooses splits that decrease impurity (Gini or Entropy), resulting in more homogeneous branches.\n",
        "\n",
        "# Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "\n",
        "**Ans:-** Pre-Pruning: Limits the tree's growth before fully developing it (e.g., setting max depth, min samples per leaf). Advantage: Prevents overfitting by stopping tree growth early.\n",
        "\n",
        "Post-Pruning: Trims branches after a large tree is built, removing sections that do not provide power. Advantage: Allows initially complex trees then simplifies them based on validation performance\n",
        "\n",
        "# Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "\n",
        "**Ans:-** Information Gain quantifies the reduction in impurity achieved by splitting a node on a certain feature. It helps the tree choose splits that maximize the separation between classes, leading to more accurate classification.\n",
        "\n",
        "# Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?\n",
        "\n",
        "**Ans:-** Applications: Medicine (diagnosis), finance (credit scoring), retail (customer segmentation), marketing, web services, etc.\n",
        "\n",
        "Advantages: Interpretable, handles both categorical and numerical data, no need for scaling.\n",
        "\n",
        "Limitations: Prone to overfitting, unstable (small data changes can alter the tree), may not capture complex relationships as well as some models.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e5wt4QNbHPkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 6:\n",
        "'''\n",
        " Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier using the Gini criterion\n",
        "● Print the model’s accuracy and feature importances\n",
        "'''\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train model\n",
        "clf = DecisionTreeClassifier(criterion='gini')\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Predictions\n",
        "y_pred = clf.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Feature Importances:\", clf.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRexzHhyIXIP",
        "outputId": "f5a690ee-97e3-4f73-9588-ca900520df84"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Feature Importances: [0.         0.01333333 0.56405596 0.42261071]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Question 7:\n",
        "'''\n",
        " Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree.\n",
        "'''\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "# Fully grown tree\n",
        "clf_full = DecisionTreeClassifier()\n",
        "clf_full.fit(X, y)\n",
        "acc_full = accuracy_score(y, clf_full.predict(X))\n",
        "\n",
        "# Max depth=3\n",
        "clf_pruned = DecisionTreeClassifier(max_depth=3)\n",
        "clf_pruned.fit(X, y)\n",
        "acc_pruned = accuracy_score(y, clf_pruned.predict(X))\n",
        "\n",
        "print(\"Full Tree Accuracy:\", acc_full)\n",
        "print(\"Pruned Tree Accuracy:\", acc_pruned)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHUlXlpLJqdc",
        "outputId": "54c2b599-6d9b-4644-ec87-69281ddd0525"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Tree Accuracy: 1.0\n",
            "Pruned Tree Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8:\n",
        "'''\n",
        "Write a Python program to:\n",
        "● Load the California Housing Dataset (as Boston Housing is deprecated)\n",
        "● Train a Decision Tree Regressor\n",
        "● Print the Mean Squared Error (MSE) and feature importances\n",
        "'''\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load data\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Train model\n",
        "reg = DecisionTreeRegressor()\n",
        "reg.fit(X, y)\n",
        "\n",
        "# Predictions\n",
        "y_pred = reg.predict(X)\n",
        "mse = mean_squared_error(y, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Feature Importances:\", reg.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCWPJ75SJ8JX",
        "outputId": "91325872-e0a6-4bb6-951a-07705e9d6057"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 1.0070971343301193e-31\n",
            "Feature Importances: [0.52421567 0.05084302 0.05330042 0.02782791 0.03172282 0.13181295\n",
            " 0.09460417 0.08567304]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 9:\n",
        "'''\n",
        "Write a Python program to:\n",
        "● Load the Iris Dataset\n",
        "● Tune the Decision Tree’s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "● Print the best parameters and the resulting model accuracy\n",
        "'''\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "X, y = load_iris(return_X_y=True)\n",
        "\n",
        "param_grid = {'max_depth': [2,3,4,5], 'min_samples_split': [2, 4, 6]}\n",
        "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "grid.fit(X, y)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3E-h8IFKUTr",
        "outputId": "99e75117-f740-46c5-e5da-e1ce44e09dfb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 3, 'min_samples_split': 6}\n",
            "Best Accuracy: 0.9733333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 10:\n",
        "'''\n",
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "● Handle the missing values\n",
        "● Encode the categorical features\n",
        "● Train a Decision Tree model\n",
        "● Tune its hyperparameters\n",
        "● Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "Wsq0JbndKj-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 10:\n",
        " Imagine you’re working as a data scientist for a healthcare company that wants to predict whether a patient has a certain disease. You have a large dataset with mixed data types and some missing values. Explain the step-by-step process you would follow to:\n",
        "● Handle the missing values\n",
        "● Encode the categorical features\n",
        "● Train a Decision Tree model\n",
        "● Tune its hyperparameters\n",
        "● Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        "\n",
        "# Ans:-\n",
        "Steps for handling missing values, encoding, training, tuning, evaluating Decision Tree, and business value:\n",
        "\n",
        "Step 1: Handle missing values – Use imputation (mean/mode for numerics, most frequent for categoricals).\n",
        "\n",
        "Step 2: Encode categorical features – Apply label encoding or one-hot encoding.\n",
        "\n",
        "Step 3: Train Decision Tree model – Choose criterion (e.g., Gini), fit tree to data.\n",
        "\n",
        "Step 4: Tune hyperparameters – Use grid search on max_depth, min_samples_split.\n",
        "\n",
        "Step 5: Evaluate performance – Use accuracy, precision, recall, ROC-AUC.\n",
        "\n",
        "Business Value: The model assists doctors in early disease identification, prioritizes patient care, improves medical resource allocation, and helps insurers manage risk"
      ],
      "metadata": {
        "id": "6dxrNS0eLP22"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y0Dn0wRMLu-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}